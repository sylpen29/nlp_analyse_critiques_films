{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html as lh\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = 'http://www.allocine.fr/film/fichefilm-143692/critiques/spectateurs/'\n",
    "uri_pages = '?page='\n",
    "nbPages = 400\n",
    "tags = ['//span[@class=\"stareval-note\"]', \\\n",
    "        '//div[@class=\"content-txt review-card-content\"]' ]\n",
    "cols = ['Note', 'Description' ]\n",
    " \n",
    "page = requests.get(url)\n",
    "doc = lh.fromstring(page.content)\n",
    " \n",
    "def getPage(url):\n",
    "    page = requests.get(url)\n",
    "    doc = lh.fromstring(page.content)\n",
    " \n",
    "    # Get the Web data via XPath\n",
    "    content = []\n",
    "    for i in range(len(tags)):\n",
    "        content.append(doc.xpath(tags[i]))\n",
    " \n",
    "    # Gather the data into a Pandas DataFrame array\n",
    "    df_liste = []\n",
    "    for j in range(len(tags)):\n",
    "        tmp = pd.DataFrame([content[j][i].text_content().strip() for i in range(len(content[i]))], columns=[cols[j]])\n",
    "        tmp['key'] = tmp.index\n",
    "        df_liste.append(tmp)\n",
    " \n",
    "    # Build the unique Dataframe with one tag (xpath) content per column\n",
    "    liste = df_liste[0]\n",
    "    for j in range(len(tags)-1):\n",
    "        liste = liste.join(df_liste[j+1], on='key', how='left', lsuffix='_l', rsuffix='_r')\n",
    "        liste['key'] = liste.index\n",
    "        del liste['key_l']\n",
    "        del liste['key_r']\n",
    "     \n",
    "    return liste\n",
    " \n",
    "# def getPages(_nbPages, _url):\n",
    "#     liste_finale = pd.DataFrame()\n",
    "#     for i in range (_nbPages):\n",
    "#         liste = getPage(_url + uri_pages + str(i+1))\n",
    "#         liste_finale = pd.concat([liste_finale, liste], ignore_index=True)\n",
    "#     return liste_finale\n",
    " \n",
    "# liste_totale = getPages(nbPages, url)\n",
    "# liste_totale.to_csv('./allocine_inception_avis.csv', index=False, quoting=csv.QUOTE_NONNUMERIC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### utiliser les expressions régulières "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "REMPLACE_SANS_ESPACE = re.compile(\"[;:!\\'?,\\\"()\\[\\]]\")\n",
    "REMPLACE_AVEC_ESPACE = re.compile(\"()|(\\-)|(\\/)|[.]\")\n",
    "PUR_NOMBRE = re.compile(\"[0-9]\")\n",
    "  \n",
    "def setClassBin(i):\n",
    "    if (float(i.replace(',', '.')) > 3):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "      \n",
    "def preprocess(txt):\n",
    "    txt = [PUR_NOMBRE.sub(\"\", (str(line)).lower()) for line in txt] # retire les nombres (comme les années)\n",
    "    txt = [line.replace('\\n', ' ')  for line in txt] # Retire les \\n (retours chariots)\n",
    "    txt = [REMPLACE_SANS_ESPACE.sub(\"\", line.lower()) for line in txt]\n",
    "    txt = [REMPLACE_AVEC_ESPACE.sub(\" \", line) for line in txt]\n",
    "    return txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### préparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\UTILIS~1\\AppData\\Local\\Temp/ipykernel_29052/2883797296.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0myList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msetClassBin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNote\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Note'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "def remplace(i):\n",
    "    if (float(i.replace(',', '.')) > 3):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    " \n",
    "yList = [remplace(x) for x in X.Note]\n",
    "y = pd.DataFrame(yList)\n",
    "X = X.drop('Note', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilisation stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\UTILIS~1\\AppData\\Local\\Temp/ipykernel_29052/1553826510.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Description'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfrench_stopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'french'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfiltre_stopfr\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;32mlambda\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfrench_stopwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Description'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltre_stopfr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X['Description'] = pd.DataFrame(preprocess(X['Description']))\n",
    "french_stopwords = set(stopwords.words('french'))\n",
    "filtre_stopfr =  lambda text: [token for token in text if token.lower() not in french_stopwords]\n",
    "X['Description'] = [' '.join(filtre_stopfr(word_tokenize(item))) for item in X['Description']]\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cce956dd8b59511f520788cd9362dddc117670ac5ef39c9ede8ba85a43b854a0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
