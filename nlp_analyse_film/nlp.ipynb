{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse de texte et traitement du langage naturel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\utilisateur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\utilisateur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import des bibliothèques\n",
    "import requests\n",
    "import lxml.html as lh\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import FrenchStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping\n",
    "url = 'http://www.allocine.fr/film/fichefilm-143692/critiques/spectateurs/'\n",
    "uri_pages = '?page='\n",
    "nbPages = 400\n",
    "tags = ['//span[@class=\"stareval-note\"]', \\\n",
    "        '//div[@class=\"content-txt review-card-content\"]' ]\n",
    "cols = ['Note', 'Description' ]\n",
    " \n",
    "page = requests.get(url)\n",
    "doc = lh.fromstring(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition\n",
    "def getPage(url):\n",
    "    page = requests.get(url)\n",
    "    doc = lh.fromstring(page.content)\n",
    " \n",
    "    # Get the Web data via XPath\n",
    "    content = []\n",
    "    for i in range(len(tags)):\n",
    "        content.append(doc.xpath(tags[i]))\n",
    " \n",
    "    # Gather the data into a Pandas DataFrame array\n",
    "    df_liste = []\n",
    "    for j in range(len(tags)):\n",
    "        tmp = pd.DataFrame([content[j][i].text_content().strip() for i in range(len(content[i]))], columns=[cols[j]])\n",
    "        tmp['key'] = tmp.index\n",
    "        df_liste.append(tmp)\n",
    " \n",
    "    # Build the unique Dataframe with one tag (xpath) content per column\n",
    "    liste = df_liste[0]\n",
    "    for j in range(len(tags)-1):\n",
    "        liste = liste.join(df_liste[j+1], on='key', how='left', lsuffix='_l', rsuffix='_r')\n",
    "        liste['key'] = liste.index\n",
    "        del liste['key_l']\n",
    "        del liste['key_r']\n",
    "     \n",
    "    return liste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPages(_nbPages, _url):\n",
    "    liste_finale = pd.DataFrame()\n",
    "    for i in range (_nbPages):\n",
    "        liste = getPage(_url + uri_pages + str(i+1))\n",
    "        liste_finale = pd.concat([liste_finale, liste], ignore_index=True)\n",
    "    return liste_finale\n",
    " \n",
    "liste_totale = getPages(nbPages, url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### création csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_totale = getPages(nbPages, url)\n",
    "liste_totale.to_csv('allocine_inception_avis_v2.csv', index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Note</th>\n",
       "      <th>Description</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5,0</td>\n",
       "      <td>Après le chef d'oeuvre super-héroïque The Dark...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5,0</td>\n",
       "      <td>C’est fou ce qu’on aime détester Christopher N...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5,0</td>\n",
       "      <td>CHEF D’ŒUVRE ! Le film est absolument parfait ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5,0</td>\n",
       "      <td>Un film aussi novateur que complexe, dont la m...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3,5</td>\n",
       "      <td>Le meilleur blockbuster de 2010 a pour thème l...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>4,0</td>\n",
       "      <td>Superbe film. Très originale et plaisant à reg...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>5,0</td>\n",
       "      <td>Ce film est très bien , mise a part les 30 pre...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>5,0</td>\n",
       "      <td>Un film génialissime sous tous points: scénari...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>4,0</td>\n",
       "      <td>Un point de vue intéressant du réalisateur qui...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>5,0</td>\n",
       "      <td>Excellent et déroutant a la fois. J'aime comme...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Note                                        Description  key\n",
       "0     5,0  Après le chef d'oeuvre super-héroïque The Dark...    0\n",
       "1     5,0  C’est fou ce qu’on aime détester Christopher N...    1\n",
       "2     5,0  CHEF D’ŒUVRE ! Le film est absolument parfait ...    2\n",
       "3     5,0  Un film aussi novateur que complexe, dont la m...    3\n",
       "4     3,5  Le meilleur blockbuster de 2010 a pour thème l...    4\n",
       "...   ...                                                ...  ...\n",
       "5995  4,0  Superbe film. Très originale et plaisant à reg...   10\n",
       "5996  5,0  Ce film est très bien , mise a part les 30 pre...   11\n",
       "5997  5,0  Un film génialissime sous tous points: scénari...   12\n",
       "5998  4,0  Un point de vue intéressant du réalisateur qui...   13\n",
       "5999  5,0  Excellent et déroutant a la fois. J'aime comme...   14\n",
       "\n",
       "[6000 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('allocine_inception_avis_V2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 2 : Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retirer les bruits des commentaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "REMPLACE_SANS_ESPACE = re.compile(\"[;:!\\'?,\\\"()\\[\\]]\")\n",
    "REMPLACE_AVEC_ESPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)|[.]\")\n",
    "\n",
    "def preprocess(txt):\n",
    "    txt = [line.replace('\\n', ' ')  for line in txt] # Retire les \\n (retours chariots)\n",
    "    txt = [REMPLACE_SANS_ESPACE.sub(\"\", line.lower()) for line in txt]\n",
    "    txt = [REMPLACE_AVEC_ESPACE.sub(\" \", line) for line in txt]\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simplification des données de commentaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('./allocine_inception_avis_V2.csv')\n",
    "\n",
    "X['Description'] = pd.DataFrame(preprocess(X['Description']))\n",
    "french_stopwords = set(stopwords.words('french'))\n",
    "filtre_stopfr =  lambda text: [token for token in text if token.lower() not in french_stopwords]\n",
    "X['Description'] = [' '.join(filtre_stopfr(word_tokenize(item))) for item in X['Description']]\n",
    "\n",
    "stemmer = FrenchStemmer()\n",
    "X['Description'] = [stemmer.stem(w) for w in X['Description']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### affichage des mots inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seront', 'mon', 'sommes', 'eut', 'étantes', 'étants', 'de', 'mes', 'ayant', 'vos', 'ce', 'ait', 'le', 'ayons', 'aurez', 'aux', 'eue', 'est', 'fus', 'aura', 'fut', 'et', 'd', 'suis', 'été', 'étée', 'ou', 'étaient', 'ayants', 'auront', 'fussions', 'avions', 'ton', 'fussent', 'étais', 'ses', 'aient', 'ta', 'me', 'êtes', 'ces', 'soit', 'eus', 'eues', 'se', 'mais', 'notre', 'la', 'seras', 'toi', 'fût', 'eusse', 'un', 'au', 'aviez', 'ayante', 'seriez', 'furent', 'ayez', 'fusse', 'tu', 'son', 'nous', 'avec', 'avaient', 'tes', 'auras', 'as', 'aurait', 'avons', 'que', 'étiez', 'sera', 'c', 'serait', 'fussiez', 'les', 'dans', 'en', 'auraient', 'ma', 'serais', 'serez', 's', 'pour', 'qu', 't', 'était', 'serai', 'soyez', 'du', 'eussent', 'avez', 'eusses', 'je', 'n', 'sa', 'eu', 'qui', 'sont', 'ils', 'avait', 'serions', 'avais', 'étante', 'eurent', 'sois', 'on', 'auriez', 'fusses', 'aurais', 'l', 'aie', 'elle', 'te', 'ne', 'étés', 'ai', 'eussiez', 'seraient', 'une', 'aies', 'fûtes', 'pas', 'étions', 'il', 'étant', 'étées', 'par', 'même', 'vous', 'sur', 'fûmes', 'eussions', 'y', 'eux', 'moi', 'ayantes', 'eûmes', 'soyons', 'ont', 'aurons', 'm', 'à', 'eût', 'soient', 'des', 'lui', 'aurai', 'leur', 'eûtes', 'j', 'aurions', 'votre', 'es', 'nos', 'serons'}\n"
     ]
    }
   ],
   "source": [
    "print(french_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note\n",
      "Description\n",
      "key\n",
      "=======================\n",
      "Note\n",
      "Description\n"
     ]
    }
   ],
   "source": [
    "for ok in X:\n",
    "    print (ok)\n",
    "    \n",
    "X=X.drop('key',axis=1)\n",
    "print(\"=======================\")\n",
    "\n",
    "for ok in X:\n",
    "    print (ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 3: Préparation des libellés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setClassBin(i):\n",
    "    if (float(i.replace(',', '.')) > 3):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    " \n",
    "yList = [setClassBin(x) for x in X.Note]\n",
    "y = pd.DataFrame(yList, columns=['classe'])\n",
    "#X = X.drop('Note', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Composition de X: \\n\")\n",
    "for k in X:\n",
    "    print(k)\n",
    "\n",
    "print(\"====================================================\")\n",
    "\n",
    "print(\"Composition de y: \\n\")\n",
    "for kk in y:\n",
    "    print(kk)\n",
    "\n",
    "print(\"====================================================\")\n",
    "\n",
    "print(\"Contenue de y[classe]: \\n\")\n",
    "for kkk in y['classe']:\n",
    "    print(kkk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape de y: \", y.shape)\n",
    "print(\"Shape de X: \", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Labels dans X: \\n\")\n",
    "for a in X:\n",
    "    print(a)\n",
    "print(\"========================\")\n",
    "print(\"Labels dans y: \\n\")\n",
    "for b in y:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 4 : Finalisation du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['Description'], y['classe'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in X_train:\n",
    "#    print(i)\n",
    "\n",
    "#print(type(X_train[\"Description\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in y_train:\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vérifier le contenue car bug avec les espaces\n",
    "#mis en com car trop de texte\n",
    "\n",
    "#for op in X['Description']:\n",
    "#    print (op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorisation des mots (sac de mots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "Vectorizer = CountVectorizer(binary=True)\n",
    "Vectorizer.fit(X_train)\n",
    " \n",
    "X_train_vectorized = Vectorizer.transform(X_train)\n",
    "X_test_vectorized = Vectorizer.transform(X_test)\n",
    "pd.DataFrame(X_train_vectorized.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 5 : Entrainement du modèle\n",
    "\n",
    "- hyperparamètre __c__ \n",
    "    - Objectif : trouver le meilleur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    logisRegre = LogisticRegression(C=c)\n",
    "    logisRegre.fit(X_train_vectorized, y_train)\n",
    "    print (\"Précision pour C=%s: %s\" % (c, accuracy_score(y_test, logisRegre.predict(X_test_vectorized))))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "pred=logisRegre.predict(X_test_vectorized[1])\n",
    "print(pred, y_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meilleur paramètre c = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 6 : Analyse des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entrainer le modèle à partir du paramètre c = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele_final = LogisticRegression(C=1)\n",
    "modele_final.fit(X_train_vectorized, y_train)\n",
    "\n",
    "\n",
    "print (\"Précision: %s\" % accuracy_score(y_test, modele_final.predict(X_test_vectorized)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = modele_final.predict(X_test_vectorized)\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cf_matrix, linewidths=1, annot=True, fmt='g')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cce956dd8b59511f520788cd9362dddc117670ac5ef39c9ede8ba85a43b854a0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
